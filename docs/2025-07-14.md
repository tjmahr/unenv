<!--- Timestamp to trigger book rebuilds: 2025-07-21 15:27:22.596553 --->



## July 2025 (Smaller bits)

<small>Source: <code>2025-07-14.Rmd</code></small>

*The other July 2025 file compiles a Stan model, so let's use a separate
file to avoid rebuilding that entry unnecessarily.*

### Scrapped helper functions for a list of models

I was making a notebook with a list of related models, like


``` r
m <- list(
  mpg_wt = lm(mpg ~ wt, mtcars),
  mpg_disp = lm(mpg ~ disp, mtcars),
  mpg_disp_wt = lm(mpg ~ disp + wt, mtcars),
  mpg_disp_wt_int = lm(mpg ~ disp * wt, mtcars),
  hp_wt = lm(hp ~ wt, mtcars),
  hp_disp = lm(hp ~ disp, mtcars),
  hp_disp_wt = lm(hp ~ disp + wt, mtcars),
  hp_disp_wt_int = lm(hp ~ disp * wt, mtcars)
)
```

I want to select a subset of models and `anova()` them, so I made a quick
tidyselect function and an S3 method method of lists with `anova()`:


``` r
library(tidyverse)

list_select <- function(l, ...) {
  pos <- tidyselect::eval_select(c(...), l)
  rlang::set_names(l[pos], names(pos))
}

anova.list <- function(object) {
  do.call(anova, unname(object))
}

m |> 
  list_select(starts_with("mpg")) |> 
  list_select(matches("disp")) |> 
  anova()
#> Analysis of Variance Table
#> 
#> Model 1: mpg ~ disp
#> Model 2: mpg ~ disp + wt
#> Model 3: mpg ~ disp * wt
#>   Res.Df    RSS Df Sum of Sq      F   Pr(>F)   
#> 1     30 317.16                                
#> 2     29 246.68  1    70.476 11.694 0.001942 **
#> 3     28 168.75  1    77.934 12.931 0.001227 **
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

anova(m$mpg_disp, m$mpg_disp_wt, m$mpg_disp_wt_int)
#> Analysis of Variance Table
#> 
#> Model 1: mpg ~ disp
#> Model 2: mpg ~ disp + wt
#> Model 3: mpg ~ disp * wt
#>   Res.Df    RSS Df Sum of Sq      F   Pr(>F)   
#> 1     30 317.16                                
#> 2     29 246.68  1    70.476 11.694 0.001942 **
#> 3     28 168.75  1    77.934 12.931 0.001227 **
#> ---
#> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

`list_select()` is extremely basic. It's based on the examples in the
`tidyselect::eval_select()` documentation. 

For `list_select()`, the closest option available from purrr (the
tidyverse package for working on lists) `purrr::keep_at()`:


``` r
m |> 
  purrr::keep_at(function(x) startsWith(x, "mpg")) |> 
  str(max.level = 1)
#> List of 4
#>  $ mpg_wt         :List of 12
#>   ..- attr(*, "class")= chr "lm"
#>  $ mpg_disp       :List of 12
#>   ..- attr(*, "class")= chr "lm"
#>  $ mpg_disp_wt    :List of 12
#>   ..- attr(*, "class")= chr "lm"
#>  $ mpg_disp_wt_int:List of 12
#>   ..- attr(*, "class")= chr "lm"
```


### Model condition number and `kappa()`

A colleague got the following warning when fitting a regression model in Python:

> The condition number is large, 3.11e+03. This might indicate that
> there are strong multicollinearity or other numerical problems.

We can compute this [condition
number](https://en.wikipedia.org/wiki/Condition_number) in R via
`kappa()`


``` r
m_mpg_disp_wt_int <- lm(mpg ~ disp * wt, mtcars)
kappa(m_mpg_disp_wt_int, exact = TRUE)
#> [1] 8508.152
```

This kappa score indicates *something* about sensitivity or stability in
the model. "The condition number bounds how much the solution *z* of a
system of equations *Az*=*c* can change, on a relative basis, when its
components *A* and *c* are changed," says [whuber on
CV](https://stats.stackexchange.com/a/168276/14825).

R computes its default kappa from the ratio of the first and last
singular values of the upper triangle of the model's QR matrix. (I read
the [source
code](https://github.com/wch/r-source/blob/637e502dbc868d39f0813a6a2a5ef0469fe8e73e/src/library/base/R/kappa.R#L97-L121).)


``` r
zero_out_lower_tri <- function(m) { m[lower.tri(m)] <- 0; m }
d <- m_mpg_disp_wt_int$qr$qr |> 
  # there are 4 columns, so we are making a square
  _[1:4, 1:4] |>
  zero_out_lower_tri() |> 
  svd() |> 
  _$d

d[1] / d[length(d)]
#> [1] 8508.152
```

There is a lot of mathematical indirection here but the intuition I'm
hanging onto is that if the [SVD is warping a "circle" into an
"ellipse"](https://en.wikipedia.org/wiki/Singular_value_decomposition#Intuitive_interpretations),
the ratio in kappa is the ratio of longest and shortest axes in that
ellipse.


We can reduce this condition number by (roughly) centering our predictors:


``` r
mean(mtcars$disp)
#> [1] 230.7219
mtcars$disp_230 <- mtcars$disp - 230 

mean(mtcars$wt)
#> [1] 3.21725
mtcars$wt_3 <- mtcars$wt - 3 

m_mpg_disp_wt_int <- lm(mpg ~ disp_230 * wt_3, mtcars)
kappa(m_mpg_disp_wt_int, exact = TRUE)
#> [1] 447.5556
```

I prefer kind of rough centering to nice round numbers so that the
intercept can be easily described, and the centering constants can be
remembered. When more exact centering is needed, I do full on
*z*-scores instead:


``` r
mtcars$z_disp <- mtcars$disp |> scale() |> as.vector()
mtcars$z_wt <- mtcars$wt |> scale() |> as.vector()

m_mpg_disp_wt_int <- lm(mpg ~ z_disp * z_wt, mtcars)
kappa(m_mpg_disp_wt_int, exact = TRUE)
#> [1] 5.065835
```

As we can see, this transformation made a tremendous improvement in
condition number.

*Why doesn't R raise a warning?* There are probably lots of good reasons
to not warn by default, because we are dealing with a diagnostic score
and rules of thumb for interpreting it. That said, I was not able to
find a clear answer from an R (or S) author about why R doesn't warn
about the condition number or multicollinearity.

### Resuming a renv project

Steps for resuming a renv project when you don't care about restoring
the previous package environment.

  - Install renv anew and then do `renv::record("renv@1.1.4")` or
    whatever to record that version.

  - Install the packages used by the project. We can use `renv::update()` or 
    install as needed as we run code in the project's files.
    
  - Take a `renv::snapshot()`.
  
Note that the way to record an updated version of R is with `renv::snapshot()`.
